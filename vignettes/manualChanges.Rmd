---
title: "BayesGP: manual changes to model file"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BayesGP: Manual Changes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r data}
#devtools::install_github("Bayes-GP/BayesGP", ref='development')   
data('bacteria', package= 'MASS')
bacteria$Yresp = as.numeric(bacteria$y == 'y')
bacteria$treatment = as.numeric(bacteria$trt != 'placebo')
bacteria$week2 = as.numeric(bacteria$week >0)
bacteria$ones = 1

summary(glm(Yresp ~ + week2 + treatment, data=bacteria, family=binomial))$coef
```



```{r bayesGp}
res = BayesGP::model_fit(Yresp~ week2 + treatment +

                           f(ID, model ="IID", sd.prior= list(prior= "exp",
                          param =list(u =1, alpha=0.5))),
                           aghq_k = 10,
#                         adfun.options = list(inner.control = list(tol=1e-9)),
                           data = bacteria, family='Binomial', size = 'ones')

summary(res)
# make summary like glm, summary(), returns a list, with a print method
# so we can do summary(res)$coef
```


```{r bayesBrms, eval=FALSE}
library(brms)
fitBrms = brm(
  Yresp  ~ week2 + treatment + (1|ID),
  data = bacteria, family='bernoulli',  
  prior= set_prior("normal(5, 0.001)", class="sd")
)
fitBrms2 = rstan::extract(fitBrms$fit)
library(INLA)
fitInla = INLA::inla(
  Yresp ~ week2 + treatment+ f(ID, initial=-3.373762, fixed=TRUE),
  data = bacteria, 
  family='binomial')
fitInla$summary.fixed
```




make a function to evaluate likelihood, check the maximization

```{r adFun}
theDens = TMB::MakeADFun(
  data = res$mod$optresults$ff$env$data, 
  parameters = res$mod$optresults$ff$env$parameters,
  hessian=TRUE, silent=TRUE,
  DLL='BayesGP')
```


test to see if we get a different mode if re-optimize
```{r makeAdFun}
theDens2 = function(W, theta) {
  theDens$fn(c(W, theta))
}
theGr2 = function(W, theta) {
  theDens$gr(c(W, theta))[1:length(W)]
}
theHessian2 = function(W, theta) {
  theDens$gr(c(W, theta))[1:length(W)]  
}
```

```{r tesAdFun, cache=TRUE, eval=FALSE}
for(Dconfig in c(3,5, 8)) {
thetaHere = res$mod$modesandhessians$theta[Dconfig]

startHere =   rnorm(
    length(res$mod$modesandhessians$mode[[Dconfig]]),
    mean=res$mod$modesandhessians$mode[[Dconfig]],
    sd = 0.03)
optHere = optim(
  startHere,
  fn = theDens2, gr = theGr2,
  method="BFGS",
  control = list(maxit=1e6, reltol=1e-9),
  theta = thetaHere)
optHere2 = optim(
  startHere,
  fn = theDens2, gr = theGr2,
  method="SANN",
  control = list(maxit=1e5, reltol=1e-8),
  theta = thetaHere)
print(c(sd=exp(thetaHere)^(-0.5),
  orig = res$mod$modesandhessians$mode[[Dconfig]][51], 
  new = optHere$par[51], val = optHere$value,
  new2 = optHere2$par[51], val2 = optHere2$value))
}
```


impolrtant sampling weighted mle
```{r isFitFunctions}
importanceSampleSkewT = function(Nsamps, mode, df, theta, densFunAll, skewScale = 1,  threshold = 0.999, 
                                 dataForADFun, parametersForADFun) {

if(missing(densFunAll)) {
  cat("making ad fun")
  densFunAll = TMB::MakeADFun(
  data = dataForADFun, 
  parameters = parametersForADFun,
  hessian=TRUE, silent=TRUE,
  DLL='BayesGP')
  cat("... done\n")

}

    

hessian = densFunAll$he(c(mode, theta))
hessian = hessian[1:length(mode), 1:length(mode)]
hessian = as.matrix(Matrix::nearPD(hessian)$mat)
theEigen = eigen(hessian)
sigma1 = (theEigen$vectors) %*% diag(1/theEigen$values) %*% t(theEigen$vectors)  
sigma2 = ((df-2)/df)*sigma1
sigma2 = (sigma2 + t(sigma2))/2

oneHess = function(x, ind, mode, theta){
  theArgs = mode 
  theArgs[ind] = x
  densFunAll$he(c(theArgs, theta))[ind,ind]
}

thirdDeriv = mapply(oneHess, 
  x = mode, ind = 1:length(mode),
  MoreArgs = list(mode = mode, theta = theta)
)

skew = thirdDeriv * skewScale

samples_T1 = sn::rmst(
  Nsamps, xi = mode, 
  Omega = sigma2, 
  alpha =skew,
  nu=df)

densProp = sn::dmst(
  samples_T1,xi = mode, 
  Omega = sigma2, alpha =skew,
  nu=df,
  log=TRUE)

densData = -apply(cbind(samples_T1, theta), 1, densFunAll$fn)


theProb = densData - densProp
theProb = theProb - max(theProb)
theProb = exp(theProb)
theProb = theProb/sum(theProb)



theOrder = order(theProb, decreasing=TRUE)
toKeep = min(which(cumsum(theProb[theOrder]) > 0.999))
toKeep = which(theOrder < toKeep)

sampsSub = samples_T1[toKeep, ]

# weights in msn.mle should sum to number of samples
theW = theProb[toKeep]
theW = length(theW) * theW / sum(theW)

theSnFit = sn::msn.mle(
  x = matrix(1,nrow(sampsSub), 1),
  y=sampsSub, 
  opt.method='BFGS', 
  w = theW,
  start = list(
  beta = matrix(apply(sampsSub, 2, mean), nrow=1),
  Omega = var(sampsSub),
  alpha = skew/10
  ),
  trace = FALSE,
  control=list( 
   parscale = rep(c(1e-1, 1e4), each=length(mode)))
)

theSnFit$dp$moment1 = apply(samples_T1 *theProb, 2, sum)

theSnFit$dp
}
```


```{r isFitTest, eval=FALSE}
Dconfig = 1
stuff = importanceSampleSkewT(
  mode = res$mod$modesandhessians$mode[[Dconfig]],
  theta = as.list(res$mod$modesandhessians$theta)[[Dconfig]],
    Nsamps = 2e5,
   dataForADFun = res$mod$optresults$ff$env$data,
   parametersForADFun = res$mod$optresults$ff$env$parameters,
    df = 40, 
    skewScale = 1,
   threshold = 0.999
)
```

```{r isFit, cache=TRUE}
fitMle = parallel::mcmapply(
  importanceSampleSkewT,
  mode = res$mod$modesandhessians$mode,
  theta = as.list(res$mod$modesandhessians$theta),
  MoreArgs = list( 
    Nsamps = 3e5,
    df = 40, 
    skewScale = 1,
   threshold = 0.999,
   densFunAll=theDens
  ),
  mc.cores = 1, 
  SIMPLIFY=FALSE
)
```

```{r plotFitMle, fig.cap = 'Intercept, SN (blue) and N (red)', fig.subcap = 1:length(fitMle), fig.height=4,fig.width=4}
par(mar= c(2,0,0,0), mgp=c(1,0.5, 0), bty='n')
Sx = seq(0,10,len=1001)
Dpar = 51

sqrt2overpi = sqrt(2/pi)

for(Dconfig  in 1:length(fitMle)) {

theScale = sqrt(fitMle[[Dconfig]]$Omega[Dpar,Dpar])
delta = fitMle[[Dconfig]]$alpha[Dpar] / sqrt(1 + fitMle[[Dconfig]]$alpha[Dpar]^2)
theMeanSn = fitMle[[Dconfig]]$beta[1,Dpar] + theScale * delta * sqrt2overpi

theY = cbind(
  n =   dnorm(Sx, 
    mean=res$mod$modesandhessians$mode[[Dconfig]][Dpar], 
    sd=sqrt(solve(res$mod$modesandhessians$H[[Dconfig]])[Dpar,Dpar])
  ),
  sn = sn::dsn(Sx, 
    xi = fitMle[[Dconfig]]$beta[1,Dpar],
    omega = theScale,
    alpha = fitMle[[Dconfig]]$alpha[Dpar]
  )
)

matplot(Sx, theY, xlim = c(1,8),
  type='l', xlab='',
  col=c('red','blue'))



abline(v = res$mod$modesandhessians$mode[[Dconfig]][Dpar], col='red', lwd=3)
abline(v= fitMle[[Dconfig]]$moment1[Dpar], col='blue', lwd=3, lty=2)
abline(v=theMeanSn, col='green', lwd=3,lty=3)

}

```






```{r customCpp, cache=TRUE}
theCpp =list.files(system.file("extsrc", package="BayesGP"), full.names=TRUE)
theCpp = scan(theCpp, what='a', sep='\n')

theCpp = gsub("PARAMETER_VECTOR[(]theta[)];", "DATA_VECTOR(theta);", theCpp)
theCpp = theCpp[grep("lpT [+]=", theCpp, invert=TRUE)]

theCppFile = tempfile(fileext='.cpp')
theCppFileSansExt = gsub("[.]cpp$", "", theCppFile)

theCpp = gsub("R_init_BayesGP", 
  paste0("R_init_", basename(theCppFileSansExt)),
  theCpp)


write(theCpp, theCppFile)
TMB::compile(theCppFile)
```


test optim again.
```{r theAdFun}
theDll <- dyn.load(TMB::dynlib(theCppFileSansExt))

Dconfig = 3
ffFixedTheta <- TMB::MakeADFun(
      data = c(theDens$env$data, 
        list(theta = res$mod$modesandhessians$theta[Dconfig])),
      parameters = list(W=rep(1,length(theDens$env$parameters$W))),
      DLL = theDll[[1]],
      silent=TRUE
)
```









MCMC with fixed theta

```{r mcmc, cache=TRUE}

default_option_list <- BayesGP::get_default_option_list_MCMC(
  list(chains=4, cores=4, warmup=1000))

Nsamples = 2000

options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)
rstan::rstan_options(threads_per_chain = 1)
mod <- tmbstan::tmbstan(
        ffFixedTheta,
        chains = default_option_list$chains,
        cores = default_option_list$cores,
        iter = default_option_list$warmup + Nsamples,
        warmup = default_option_list$warmup,
        seed = default_option_list$seed,
        silent = default_option_list$silent,
        laplace = default_option_list$laplace
)

allSamples = rstan::extract(mod)[[1]]
```



```{r allHIst, fig.height=4, fig.width=4, fig.cap='mcmc (hist), normal (red), sn (blue)', fig.subcap = 1:length(res$mod$modesandhessians$mode[[1]])}
par(mar = c(1.5, 0, 0,0), bty='n', mgp=c(0.5, 0.2, 0))
for(D in 1:ncol(allSamples)) {
  hist(allSamples[,D], prob=TRUE, breaks = 30, main='', 
    border=0,
    xlim = quantile(allSamples[,D], c(0.001, 0.999)), xlab='', ylab='', yaxt='n')
  Sx = seq(par('usr')[1], par('usr')[2], len=1000)
lines(Sx, 
  dnorm(Sx, 
    mean=res$mod$modesandhessians$mode[[Dconfig]][D], 
    sd=sqrt(solve(res$mod$modesandhessians$H[[Dconfig]])[D,D])
  ),
  col='red')
lines(Sx, 
  sn::dsn(Sx, 
    xi = fitMle[[Dconfig]]$beta[1,D],
    omega = sqrt(fitMle[[Dconfig]]$Omega[D,D]),
    alpha = fitMle[[Dconfig]]$alpha[D]
  ), 
  col='blue')

abline(v=fitMle[[Dconfig]]$moment1[D], col='green', lwd=3)
abline(v=mean(allSamples[,D]), col='black')

theScale = sqrt(fitMle[[Dconfig]]$Omega[D,D])
delta = fitMle[[Dconfig]]$alpha[D] / sqrt(1 + fitMle[[Dconfig]]$alpha[D]^2)
theMeanSn = fitMle[[Dconfig]]$beta[1,D] + theScale * delta * sqrt2overpi

abline(v=theMeanSn, col='blue')

}
```



```{r fromPriyanka, eval=FALSE}
thetaHere = -3.373762
exp(thetaHere)^(-1/2)
optHere = optim(res$mod$modesandhessians$mode[[Dconfig]],
  theDens2, gr = theGr2, theta = thetaHere, method="BFGS")

optHere$par

hessianHere <- numDeriv::jacobian(theGr2, optHere$par, theta = thetaHere)

isHere = forImportanceSampling(10000, mode=optHere$par, 
  hessian = hessianHere, df=20, theta=thetaHere, densFun=theDens$fn) 

isHere[51,]

interceptMode = 4.2525603

```

